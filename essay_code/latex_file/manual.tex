% -*- coding: GBK2312 -*-

%\chapter{绪论} \label{chpt:A}

\chapter{绪论}

%来自wikipedia
%百度百科 深度学习
人工智能技术,本质上是寻求以某种形式和程度上的自动化,以求在特定方面替代在各种生产与生活领域对人力资源以及人力控制的需求.其作为目前国际学界最为关注的研究领域之一,其对社会发展的影响力和推动力难以估量.

而人工智能技术所需要的具有应用价值的人工智能系统,必须能够在一定程度上模拟人的控制能力.而模拟人的控制能力,在理论上需要机器学习的手段和载体以及对相关能力特征的表述. 而ANN ( artificial neural network ,人工神经网络)与深度学习,正是被广泛运用的人工智能的载体与学习手段.

ANN 是在生物学研究的基础上,通过多学科交叉领域学界的的探索,最终衍生出的计算机科学研究领域.按照机器学习以及认知科学领域目前普遍认同的定义,人工神经网络是一种可以根据外部信息进行自适应的仿生数学或计算模型.而深度学习则是在海量的数据样本的基础上,学习其中的某些复杂的分析特性与分布规律,使得所需求的目标分析处理能力通过学习被抽象为复杂的分布式数据特征.

在计算机科学领域,由于在大量人工智能需求场景下都具有的通用性和有效性,使得如今在计算机识别和控制、统计规划、医学以及生物研究乃至社会经济等领域, ANN 和深度学习技术都是最具价值的研究方向之一.

\section{人工神经网络与神经活动研究}

%以下内容来自
%https://blog.csdn.net/jinking01/article/details/103344186?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_paycolumn_v3&utm_relevant_index=8

%来自https://www.zhihu.com/question/54139566 Frankenstein的回答

人工神经网络技术领域具有很深刻的多学科领域交叉的历史背景,可以追溯到医学和生物研究领域对人类神经活动的研究模拟. 而正是对神经系统和神经结构特性的不断模拟和数理化抽象,促进着人工神经网络形式和功能上的不断复杂化和精确化,这是一个不断进步的过程.

奥地利医生 Franz Joseph Gall 通过对人类神经组织切片的微观分析,得出了人类神经活动依赖于人体脑部的功能的论断,解释了人类神经功能的物质基础.在一定程度,这与神经网络所需求的分析能力,某种程度上依赖于人工神经网络的数理模型结构,逻辑关系上十分相似.

意大利细胞学家 Camillo Golgi 与西班牙神经组织学家 Santiago Ramón y Cajal 通过使用 Golgi 染色法等更精细的微观分析手段,确认了人类神经组织中神经元功能和结构的独立性.而神经元结构与功能上的独立性的科学发现,也为此后人工神经网络中仿神经元的计算单元设计提供了借鉴.

最终在1943年,基于 Franz Joseph Gall , Camillo Golgi 和 Santiago Ramón y Cajal 对人类神经功能运行模式的一系列深入研究, Warren McCulloch 和 Walter Pitts 首次提出借鉴已知神经细胞运行机制的数学模型 M-P 模型. M-P 模型见图 1.1 .

\begin{figure}
	\centering
	\includegraphics[scale=0.7]{Figures/mpmodel.png}
	\caption{M-P 模型}
\end{figure}
\begin{figure}
	\centering
	\includegraphics[scale=0.7]{Figures/perceptron.png}
	\caption{Perceptron 模型以及其改进模型 Adaline 网络}
\end{figure}

M-P 模型作为基于简单的函数运算和阈值逻辑来识别输入的二分类器人工神经网络,是最简单的人工神经网络的架构之一,首次在数学和计算模型领域引入仿生神经网络的思想,开辟了人工神经网络研究这个新的计算机科学领域.M-P模型的提出,证明仿神经网络的数学模型在一定程度上可以实现逻辑和算术函数映射的功能.而随后的一系列神经功能运行机制在数理上的抽象和在数学模型上的引入不断强化着人工神经网络模拟复杂映射能力.

而20世纪40年代末的 Donald Olding Hebb 通过在数学模型中引入对神经元的激活机制的抽象, 提出了用以调整其数学模型参数的 Hebb 学习规则, 以模拟神经元的选择性和差异性的激发来模拟生物神经元对外界刺激的学习机制. 1958年, Cornell 航空实验室的 Frank Rosenblatt 提出的模式识别算法感知机神经网络,即 Perceptron 神经网络,通过简单四则运算实现了结构简单的双层网络,并且数理化表述了感知机中尚无法实现的异或回路机制.Perceptron 神经网络引发了学界对神经网络结构和相关学习算法的广泛深入研究.其后, Stanford 大学教授 Bernard Widrow 和学生 Ted Hoff 也在 Perceptron 模型做出了基于 ALN ( Adaptive Linear Neuron , 适应性线性神经元)的 改进型的 Adaline 网络. Perceptron 模型和 Adaline 模型见图 1.2 .

但是上述的 M-P 模型与 Perceptron 模型及其改进型作为早期神经网络模型的代表,在 1969 年被 Marvin Minsky 和 Seymour Papert 证明其功能上的有限性,尤其是无法实现 Frank Rosenblatt 所提出的异或回路机制,这一度成为了该领域的研究瓶颈. 

但是随后, Paul Werbos 博士的误差反向传播机制,即 BP (Back-propagation,反向传播) 算法的提出,使得异或回路的实现在理论上出现了可能,但是在网络神经元结构上的限制使得 BP 算法难以得到有效利用.最终 John Hopfield 与 Hinton, G. E. 和 Sejnowski, T. J. 在多层神经网络模型中,引入全互联机制和隐单元结构,使得神经网络领域再次进入蓬勃发展时期. 而 David E. Rumelhart, Geoffrey E. Hinton 和 Ronald J. Williams 提出的非线性 sigmod 函数神经元与误差反向传播算法即 BP 算法的结合,解决了异或回路问题,并且使得相对复杂的非纯线性多层神经网络,成为人工神经网络结构的重要组成形式,使得人工神经网络的深度学习和广泛应用更具有可行性.

\section{全连接网络与卷积神经网络}
%https://blog.csdn.net/jinking01/article/details/103344186?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_paycolumn_v3&utm_relevant_index=8
基本的非纯线性多层神经网络,在研究的早期被认为在应用领域具有巨大的价值.而且在1989年,通过大量针对包含隐单元和非线性单元结构的多层神经网络中 BP 算法性能的探究,最终在理论上证明了在神经网络层数和隐藏层数足够的情况下,基本非纯线性多层连续前馈神经网络可以任意程度逼近任意的映射.

但是,实际上应用这种思想的全连接神经网络在实际运用中效果并不理想.虽然理论上全连接神经网络能够拟合任意的映射,但实际上过度复杂的神经网络结构会造成得到目标分析处理能力和参数良性收敛的失败,使得基于海量数据集的有效深度学习变得困难.因此,为增强人工神经网络在深度学习训练上的易行性,必须在其数理结构上复杂性和实际应用上的有效性中做出取舍.

在1979年,日本工程师 Kunihiko Fukushima 提出 Neocognitron 网络,并在其中引入了"卷积"和"池化"等不包含在传统非纯线性多层神经网络中的功能概念,这使得神经网络在组织结构上出现进一步的复杂化.1989年 Yann LeCun 提出的 LeNet 神经网络成为以一个系统化实现相关性概念的卷积神经网络.通过对基本非纯线性多层神经网络的针对性改进而产生的卷积神经网络,具有与传统的全连接网络不同的神经网络架构,很好的解决了全连接网络在实际应用中一部分缺陷.

\begin{figure}
\centering
\includegraphics[scale=1]{Figures/CNN3.png}
\caption{卷积神经网络结构}
\end{figure}

这是因为,在卷积神经网络在传统的全连接神经网络结构之外,还引入了以下的结构:
\begin{enumerate}
	\item 激活层 RELU : 应用非线性激励函数的非线性层,具有对线性映射性能不足进行补充,并使输出控制在一定范围内的功能,作为卷积层和输出层的一部分
	\item 池化层 POOLING : 具有在不同深度上欠采样,降低特征的维度,防止过拟合的功能
	\item 输入层 INPUT : 预处理多维输入,具有将将输入数据去均值和归一化,再在各个维度上降维形成若干不相关的特征轴功能的神经元层
	\item 卷积层 CONV : 一种基于在各神经元多维感受域下的局部感知效应的而实现参数共用的复杂计算单元层
	\item 输出层 OUTPUT : 神经网络的最后一层,由线性层和具有概率分布映射功能的$softmax$函数组成,视为多分类器
\end{enumerate}

典型卷积神经网络的基本结构见图 1.3 .

在这些新的结构中,输入层实现了复杂多维数据在进入网络前的规范化处理,复数的卷积层的并用能够更加充分的利用输入的多维特征,而池化层的欠采样功能则能够抛弃多余的多维特征并在一定程度上避免过拟合的情况,而输出层作为标签预测模型的重要构件具有求取各目标标签概率分布的功能.

而总体上来说,由于卷积神经网络存在模型参数共用和多维特征采集的机制,导致实际上模型的参数量更精简.由于卷积神经网络在模型权重参数上的有效精简,使得其无论是在深度学习训练难度还是实际使用场景中的有效性都更高.

\section{卷积神经网络与图像识别}
%来自
%https://zhuanlan.zhihu.com/p/47184529?msclkid=506087dbb97811ec8040aa32dc937a8c

神经网络在图像识别领域的应用,是推动人工神经研究领域进步的现实动力之一.在诸多的人工神经网络模型概念中,卷积神经网络是最有应用价值和研究价值的领域之一.卷积神经元相比全连接的人工神经网络,更加具有广泛应用的潜力.

1998年, Yann LeCun 与其他共同研究者在自己提出的 LeNet 卷积神经网络模型的基础上提出了改进的 CNN LeNet-5 人工神经网络用以对美国的支票等文书上的手写数字进行精确识别.

这种人工神经网络在社会经济领域的直接应用,极大地促进了人工智能领域学界对神经网络实际运行性能追求和相关算法和结构的改进,并使得标准化的人工神经网络图像识别成为衡量神经网络性能的重要指标之一.卷积神经网络相对于全连接的神经网络,能够有效避免全连接网络对多维输入向量化造成的信息损失,同时也避免了实际应用中全连接网络中大量的冗余参数造成训练困难和过拟合现象.

因此,在图像识别领域的应用上,卷积神经网络的确相对其他更原始形式的人工神经网络更加具有竞争力和实用性.

LeNet 卷积神经网络在 MNIST 手写数据集上的应用见图 1.4 .

\begin{figure}
	\centering
	\includegraphics[scale=0.2]{Figures/CNN2.jpg}
	\caption{卷积神经网络在图像识别上的应用}
\end{figure}

\chapter{神经网络应用的安全问题}

\section{神经网络安全问题综述}
% 见我的相关md文档,引用来自张玉给的几篇论文
% 各场景直接来自于那些论文

\begin{figure}
	\centering
	\includegraphics[scale=0.7]{Figures/situation.png}
	\caption{人工神经网络应用中的风险}
\end{figure}

因为人工神经网络技术在社会各领域的广泛运用,使得人工神经网络的应用项目本身变成了具有重大政治、经济乃至文化价值的影响目标.因此,围绕人工神经网络在应用上的安全性,对相关攻击手段和防御方式开始变得越来越被重视.

目前,围绕人工神经网络实际应用的各类攻击手段,其目的和手段并不统一.若不在应用场景中没有第三方情形下考虑安全问题的话,则可以通过第三方在人工神经网络应用场景中的不同参与方式,来区分不同类别安全风险的特点.现代社会的人工神经网络应用中,第三方的人工神经网络计算平台以及第三方的数据集和模型,都是潜在的第三方参与的有安全隐患的应用场景.根据这些现状,我们可以划分出第三方平台、第三方数据、第三方模型三个主要场景.

在第三方平台控制下进行训练,存在模型和数据被篡改的风险.虽然第三方平台可能实现对运行参数的透明,但仍然不能排除训练过程中暗中修改模型或训练过程计划,以及修改用户方提供的良性数据集插入有毒数据等恶意行为的存在.对这样的场景尚没有能完全消除恶意风险的手段,一般可以通过在良性环境下重复训练以调整恶意修改模型造成的效果.

在可能恶意的第三方数据集的影响下,除了通过某些方式清除有毒数据外也没有根本的解决方式.但是这种情形下的安全风险仅限于有毒数据,而无法对模型结构、训练过程计划、推理管道造成影响.

有恶意风险的第三方模型,一般在应用场景中通过互联网和源码非透明公开的 API 引入.这类型的安全风险在几类场景中是最大的,因为有毒的模型可以污染模型无关的推理管道外几乎所有的处理过程.针对这种安全风险,需要在人工神经网络输入数据的预处理阶段或是推理管道的功能上做出有效的防范.

\section{神经网络的重要攻击和防御手段}
%见我的相关md文档
%见https://www.anquanke.com/post/id/255550

\section{本文的观点}

在一定程度上,由于有效神经网络训练规模的庞大性与结构的复杂性,学界目前对神经网络后门对神经网络内部的收敛特性和内部运行机制特性的影响仍不能充分解析,因此本文选择绕开对神经网络本身内部特性的探究,选择从恶意样本与神经网络后门对神经网络的输出特性的影响进行研究.

为充分研究神经网络的输出特性,需要从大量神经网络的输出中得到分布的输出规律.本文意图通过在不同数据下进行差异化训练的同质的卷积神经网络模型在测试集中对特定对象进行分布式的预测,并通过比较不同模型间的预测差异,来从目标测试集中提取某些特定样本相对于良性样本的异常特性.

\chapter{卷积神经网络的投票式模型}

\section{MNIST数据集的使用}

MNIST数据集作为在卷积神经网络中被广泛使用的数据集

\section{卷积神经网络的选取}

本次实验选取的是在图像识别领域常用的 LeNet 卷积网络模型