## 新选题参考

> 选题理由综述

在神经网络模型训练中,对植入相关触发器后门的样本和模型的分析一直是重要的领域.对于识别模型的安全性和识别样本的恶意性,是其中重要的研究方向.
本次选题基于两个假设:恶意训练集中恶意样本占比不高,以及人具有手动分辨少量恶意样本的能力.
本次选题尝试使用目标训练集的等规模的随机子集,并以其训练若干模型,进行样本的投票式标签预测,以筛查出恶意样本.结合人工识别,评估恶意样本的影响.
因此,本次选题的重点在于降低恶意样本的漏报率,并以漏报率作为该衡量该评估方式的有效性的指标.

> 理由要点归纳
- 1.建立含有`恶意样本`的`总数据集`
    - 如何标记区分`恶意样本`?
    - 如何生成恶意样本?
- 2.建立模型并确立训练方式
    - 训练什么?`真伪二分类`还是`打标签`?
- 3.取总数据集的若干`子集`用以训练模型
    - 主要部分,具体参数参考`DCGAN的真伪值模型`还是`视觉迁移的打标签模型`,`MNIST数字识别`?
- 4.`多模型投票``漏报率`
    - 如何统计,如何分析

> 考虑方案
- 1.使用`MNIST数据集
- 3.使用`随机抽样`的方式取子集
- 4.制造恶意样本集
  - 必须满足占比低的原则
    - 是否可行:随机选定样本,将其真伪标签`误标`并且放置trigger方块
      - trigger方块如何放置?
      5.因为MNIST数据集是tuple无法修改,所以考虑复制文件直接在文件上修改数据集,数据集格式参考图片FORMAT,TEST,TRAIN 
- 5.投票逻辑
  - 不同模型得到的output是pred向量,是一个10*1的概率张量(由softmax函数得到)