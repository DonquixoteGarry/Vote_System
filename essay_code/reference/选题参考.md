## 选题参考

> 选题理由综述

在神经网络模型训练中,对植入相关触发器后门的样本和模型的分析一直是重要的领域.对于识别模型的安全性和识别样本的恶意性,是其中重要的研究方向.
本次选题基于两个假设:恶意训练集中恶意样本占比不高,以及人具有手动分辨少量恶意样本的能力.
本次选题尝试使用目标训练集的等规模的随机子集,并以其训练若干模型,进行样本的投票式标签预测,以筛查出恶意样本.结合人工识别,评估恶意样本的影响.
因此,本次选题的重点在于降低恶意样本的漏报率,并以漏报率作为该衡量该评估方式的有效性的指标.

> 理由要点归纳
- 1.建立含有`恶意样本`的`总数据集`
    - 如何标记区分`恶意样本`?
    - 如何生成恶意样本?
- 2.建立模型并确立训练方式
    - 训练什么?`真伪二分类`还是`打标签`?
- 3.取总数据集的若干`子集`用以训练模型
    - 主要部分,具体参数参考`DCGAN的真伪值模型`还是`视觉迁移的打标签模型`?
- 4.`多模型投票`
- 5.统计`漏报率`
    - 如何统计?

> 考虑方案
- 1.使用`celeba数据集`作为`真值样本集`,使用`DCGAN的真伪值模型`,规模是202599张图片
- 2.考虑使用`文件名`区分`恶意样本`并统计漏报率
  - 将恶意样本的文件名全部取大于300000的整数
- 3.使用`随机抽样`的方式取子集
  - 随机的方式显然`文件名无关`
  - 是否可行:参考DCGAN模型中基于正态分布生成fixed_noise潜向量噪音
- 4.使用GAN模型训练出一批`伪值样本集`,数量待定约5000
  - 对抗生成?
- 5.制造恶意样本集
  - 必须满足占比低的原则
  - 是否可行:随机选定样本,将其真伪标签`反标`
  - 是否可行:随机选定样本,将其真伪标签`反标`并且放置trigger方块
    - trigger方块如何放置?
- 6.数据集文件结构为`带文件名的图集`+`标签集`